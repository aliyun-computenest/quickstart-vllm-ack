apiVersion: v1
kind: Secret
metadata:
  name: acs-image-secret
  namespace: llm-model
type: kubernetes.io/dockerconfigjson
data:
  .dockerconfigjson: ewoJImF1dGhzIjogewoJCSJlZ3NsaW5nanVuLXJlZ2lzdHJ5LmNuLXd1bGFuY2hhYnUuY3IuYWxpeXVuY3MuY29tIjogewoJCQkiYXV0aCI6ICJiVzk1WVc5QU1Ua3dNekF4TlRBM05USXlPVEl3T1RwRGJuQkZVakEyTWxGdklRPT0iCgkJfQoJfQp9Cg==
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: deepseek-r1
  namespace: llm-model
  labels:
    app: deepseek-r1
spec:
  replicas: 1
  selector:
    matchLabels:
      app: deepseek-r1
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
  template:
    metadata:
      labels:
        app: deepseek-r1
        alibabacloud.com/compute-class: gpu
        alibabacloud.com/gpu-model-series: H20
        alibabacloud.com/hpn-type: "rdma"
    spec:
      imagePullSecrets:
      - name: acs-image-secret
      containers:
      - name: llm-ds-r1
        image: egslingjun-registry.cn-wulanchabu.cr.aliyuncs.com/egslingjun/inference-nv-pytorch:25.03-vllm0.8.2-pytorch2.6-cu124-20250328-serverless
        imagePullPolicy: IfNotPresent
        command:
        - sh
        - -c
        - "vllm serve /llm-model/deepseek-ai/DeepSeek-R1-GPTQ-INT8 --port 8000 --trust-remote-code --served-model-name ds --max-model-len 32768 --quantization moe_wna16 --gpu-memory-utilization 0.98 --tensor-parallel-size 8"
        resources:
          limits:
            nvidia.com/gpu: "8"
            cpu: "16"
            memory: 128Gi
        volumeMounts:
        - name: llm-model
          mountPath: /llm-model
        - name: shm
          mountPath: /dev/shm
      restartPolicy: Always
      terminationGracePeriodSeconds: 30
      volumes:
      - name: llm-model
        persistentVolumeClaim:
          claimName: llm-model
      - name: shm
        emptyDir:
          medium: Memory
          sizeLimit: 32Gi